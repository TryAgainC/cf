#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
integrated_all.py

ä¸€é”®æµç¨‹ï¼ˆå·²æŒ‰ç”¨æˆ·è¦æ±‚è°ƒæ•´ä¸º ip:port å¯ç”¨æ€§æ£€æµ‹è„šæœ¬ï¼‰ï¼š
...
ï¼ˆæ³¨ï¼šå·²å°† config_node.txt æ›¿æ¢ä¸ºè„šæœ¬å†…å›ºå®š BASE_VLESSï¼›æ‰€æœ‰é€šè¿‡çš„ ip:port å†™å…¥ okcf.txtï¼‰
"""

from __future__ import annotations
import os
import sys
import subprocess
import asyncio
import aiohttp
import time
import requests
import threading
import json
import queue
import shutil
import signal
import re
import socket
from datetime import datetime
from urllib.parse import urlparse, parse_qs, unquote, urlencode
from typing import Dict, Optional, Tuple
from concurrent.futures import ThreadPoolExecutor, as_completed
import ipaddress
from collections import defaultdict, OrderedDict

# ================== ç”¨æˆ·å¯é…ç½®åŒºåŸŸ ==================
IP_FILE = 'ip.txt'  # è¾“å…¥ IP / CIDR æ®µ
CF_IP_FILE = 'cf_ip.txt'  # masscan + è¿‡æ»¤åè¾“å‡ºçš„ ip:port åˆ—è¡¨
LOG_FILE = 'cf.log'  # æ—¥å¿—
RATE = 1000000  # masscan é€Ÿç‡
PORTS = '0-65535'  # æ‰«ææ‰€æœ‰ç«¯å£
MASSCAN_PATH = shutil.which('masscan') or 'masscan'  # masscan å¯æ‰§è¡Œè·¯å¾„ï¼ˆä¼˜å…ˆç³»ç»Ÿ PATHï¼‰

CONCURRENCY = 200  # aiohttp å¹¶å‘æ•°ï¼ˆCloudflare è¿‡æ»¤ï¼‰
TIMEOUT_SECONDS = 1.5  # aiohttp è¯·æ±‚è¶…æ—¶ï¼ˆç§’ï¼‰
BATCH_SIZE = 10000  # masscan è¾“å‡ºæ‰¹é‡è¿‡æ»¤å¤§å°

# CONFIG_NODE å·²è¢«ç”¨æˆ·è¦æ±‚ç§»é™¤ï¼Œæ”¹ä¸ºè„šæœ¬å†…å†™æ­» BASE_VLESS
# CONFIG_NODE = "config_node.txt"
OUTPUT_NODE = "cf_node.txt"  # ï¼ˆä¿ç•™å˜é‡åä»¥å…¼å®¹å…¶å®ƒé€»è¾‘ï¼Œä½†è„šæœ¬ä¸ä¼šå†™è¿™ä¸ªæ–‡ä»¶ï¼‰
BGP_FILE = "BGP.txt"  # BGP åˆ†ç±»ä¸å‘½åï¼ˆå•†å®¶: ç½‘æ®µ åˆ—è¡¨ï¼‰

XRAY_PATH = shutil.which("xray") or "/usr/local/bin/xray"  # xray å¯æ‰§è¡Œè·¯å¾„
CURL_CMD = shutil.which("curl") or "/usr/bin/curl"  # curl å¯æ‰§è¡Œè·¯å¾„

MAX_WORKERS = 5  # xray å¹¶å‘è¿›ç¨‹æ•°ï¼ˆåŒæ—¶æµ‹è¯•çš„èŠ‚ç‚¹æ•°é‡ï¼‰
LOCAL_SOCKS_BASE = 18080  # æœ¬åœ° socks èµ·å§‹ç«¯å£ï¼ˆå¤šä¸ªè¿›ç¨‹ä¾æ¬¡+1ï¼‰

XRAY_START_WAIT = 0.8  # ï¼ˆä¿ç•™é¡¹ï¼‰xray å¯åŠ¨ç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰
CURL_TIMEOUT = 12  # curl æ¯æ¬¡è¯·æ±‚æœ€å¤§è€—æ—¶ï¼ˆç§’ï¼‰
TEST_URL = "https://www.gstatic.com/generate_204"  # æ—§å­—æ®µï¼Œå…¼å®¹ä¿ç•™ï¼ˆå®é™…ä»¥ TEST_URLS ä¸ºå‡†ï¼‰
SUCCESS_HTTP_CODES = {200, 204}  # æ£€æµ‹é€»è¾‘æ”¹ä¸ºä»…æ¥å— 200/204

TMP_DIR = ".xray_tmp"  # ä¸´æ—¶ç›®å½•ï¼ˆå­˜æ”¾ä¸´æ—¶é…ç½®ï¼‰

# ---- æ–°æ£€æµ‹é€»è¾‘çš„é¢å¤–é…ç½® ----
TEST_URLS = [
    "https://www.google.com/generate_204",
    "https://www.gstatic.com/generate_204",
]  # æ¯ä¸ªèŠ‚ç‚¹ä¾æ¬¡æµ‹è¯•çš„ URL åˆ—è¡¨ï¼ˆéƒ½é€šè¿‡æ‰ç®—æˆåŠŸï¼‰
PER_URL_TRIES = 1  # æ¯ä¸ª URL éœ€è¦è¿ç»­é€šè¿‡çš„æ¬¡æ•°
SOCKS_READY_TIMEOUT = 5.0  # ç­‰å¾… socks ç«¯å£å°±ç»ªçš„æœ€é•¿æ—¶é—´ï¼ˆç§’ï¼‰
USER_AGENT = "Mozilla/5.0"  # curl ä½¿ç”¨çš„ UA
# --------------------------------

# --- Telegram æœºå™¨äººé…ç½®ï¼ˆä½ æä¾›çš„ï¼‰ ---
TG_BOT_TOKEN = "8461895834:AAG3jgP69NK8qV32EKBdkeY_Co8ksVCXv04"
TG_CHAT_ID = "1989449209"

# --- æ–°è¦æ±‚æ–‡ä»¶ï¼šæœ€ç»ˆé€šè¿‡çš„ ip:port å†™å…¥ okcf.txt ---
OK_FILE = "okcf.txt"

# ---- ä½ ç»™å®šçš„å›ºå®šæµ‹è¯•æ¨¡æ¿ï¼ˆå·²å†™æ­»ï¼‰ ----
BASE_VLESS = (
    "vless://9ec93812-41a1-4c1b-9438-f15e39566a28@1.1.1.1:22"
    "?encryption=none&security=tls&allowInsecure=1&type=ws&host=ak.zhsxsr.top&path=%2Fcsgo#TEST"
)
# ====================================================

# ------------------ æ—¥å¿—ï¼ˆæ”¹ä¸º cf.py çš„å®ç°ï¼‰ ------------------
class Logger:
    """åŒæ—¶å†™ç»ˆç«¯å’Œæ—¥å¿—æ–‡ä»¶ï¼Œå¹¶ç»™æ¯è¡ŒåŠ æ—¶é—´æˆ³"""
    def __init__(self, log_file):
        self.terminal = sys.__stdout__
        self.log = open(log_file, "w", buffering=1, encoding="utf-8")  # è¡Œç¼“å†²ï¼Œè¦†ç›–å†™

    def write(self, message):
        if message:
            # é€è¡ŒåŠ æ—¶é—´æˆ³ï¼ˆä¿ç•™ç©ºè¡Œï¼‰
            lines = message.splitlines(True)
            ts = datetime.now().strftime("[%Y-%m-%d %H:%M:%S] ")
            message = "".join(ts + ln if ln.strip() else ln for ln in lines)
        self.terminal.write(message)
        self.log.write(message)

    def flush(self):
        self.terminal.flush()
        self.log.flush()

# å°† stdout/stderr é‡å®šå‘åˆ° Loggerï¼ˆsubprocess çš„è¾“å‡ºä»ç”¨ PIPE å•ç‹¬å¤„ç†ï¼‰
sys.stdout = Logger(LOG_FILE)
sys.stderr = sys.stdout


# -------------------- Telegram --------------------
def send_telegram(text: str) -> None:
    api = f"https://api.telegram.org/bot{TG_BOT_TOKEN}/sendMessage"
    payload = {"chat_id": TG_CHAT_ID, "text": text}
    try:
        r = requests.post(api, data=payload, timeout=10)
        if r.status_code != 200:
            print(f"[WARN] Telegram é€šçŸ¥å¤±è´¥ï¼šHTTP {r.status_code} {r.text[:200]}")
    except Exception as e:
        print(f"[WARN] Telegram é€šçŸ¥å¼‚å¸¸ï¼š{e}")


# -------------------- masscan + è¿‡æ»¤ --------------------
async def check_ipport_for_cf(ip: str, port: int, session: aiohttp.ClientSession) -> bool:
    url = f"http://{ip}:{port}/cdn-cgi/trace"
    try:
        async with session.get(url, timeout=aiohttp.ClientTimeout(total=TIMEOUT_SECONDS),
                               allow_redirects=False) as resp:
            text = await resp.text()
            tl = text.lower()
            if ("400 the plain http request was sent to https port" in tl and "cloudflare" in tl) or (
                    "visit_scheme=http" in tl):
                return True
            return False
    except Exception:
        return False


async def filter_batch_and_write(open_ipports, out_file):
    connector = aiohttp.TCPConnector(limit=CONCURRENCY, force_close=True)
    timeout = aiohttp.ClientTimeout(total=TIMEOUT_SECONDS)
    async with aiohttp.ClientSession(connector=connector, timeout=timeout) as session:
        sem = asyncio.Semaphore(CONCURRENCY)

        async def bound(ip, port):
            async with sem:
                ok = await check_ipport_for_cf(ip, port, session)
                return ip, port, ok

        tasks = [bound(ip, port) for (ip, port) in open_ipports]
        for fut in asyncio.as_completed(tasks):
            ip, port, ok = await fut
            if ok:
                out_file.write(f"{ip}:{port}\n")
                out_file.flush()


def pump_stderr_to_log(stream):
    """
    masscan çš„è¿›åº¦å¤šç”¨ '\r' å›è½¦åˆ·æ–°ï¼Œè¿™é‡ŒæŠŠ '\r' ä¹Ÿå½“ä½œä¸€è¡Œç»“æŸå†™å‡ºå»ï¼Œ
    è¿™æ · cf.log å’Œç»ˆç«¯éƒ½èƒ½å®æ—¶çœ‹åˆ°æ¯æ¬¡åˆ·æ–°ã€‚
    """
    buf = ""
    while True:
        ch = stream.read(1)
        if ch == "":  # EOF
            if buf:
                sys.stdout.write(buf + "\n")
                sys.stdout.flush()
            break
        if ch in ("\r", "\n"):
            sys.stdout.write(buf + "\n")
            sys.stdout.flush()
            buf = ""
        else:
            buf += ch


def run_masscan_scan_and_filter():
    if not os.path.isfile(IP_FILE):
        print(f"[ERROR] {IP_FILE} ä¸å­˜åœ¨ï¼")
        sys.exit(1)

    ip_targets = []
    with open(IP_FILE, 'r') as f:
        for line in f:
            line = line.strip()
            if not line or line.startswith('#'):
                continue
            ip_targets.append(line)
    if not ip_targets:
        print("[ERROR] ip.txt é‡Œæ²¡æœ‰æœ‰æ•ˆçš„ IP æˆ– CIDR")
        sys.exit(1)

    # æ¸…ç©ºè¾“å‡ºæ–‡ä»¶
    with open(CF_IP_FILE, 'w'):
        pass

    cmd = [
        MASSCAN_PATH,
        *ip_targets,
        f'-p{PORTS}',
        '--rate', str(RATE),
        '-oL', '-'          # ç»“æœï¼ˆopen ...ï¼‰èµ° stdout
    ]
    print(f"[+] å¯åŠ¨ masscanï¼š{' '.join(cmd)}")

    # æ³¨æ„ï¼šstderr=PIPEï¼Œç”¨çº¿ç¨‹æ³µåˆ°æ—¥å¿—/ç»ˆç«¯ï¼›stdout=PIPEï¼Œç”¨ä¸»çº¿ç¨‹è§£æ open è¡Œ
    proc = subprocess.Popen(
        cmd,
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE,
        text=True,
        bufsize=1
    )

    # å¼€çº¿ç¨‹å®æ—¶è½¬å‘ masscan çš„è¿›åº¦ï¼ˆstderrï¼‰åˆ°æ—¥å¿—+ç»ˆç«¯
    thr = threading.Thread(target=pump_stderr_to_log, args=(proc.stderr,), daemon=True)
    thr.start()

    open_batch = []
    count_total = 0
    t0 = time.time()

    with open(CF_IP_FILE, 'a') as fout:
        # é€è¡Œè§£æ masscan stdout çš„ open ç»“æœ
        for line in proc.stdout:
            line = line.strip()
            if not line:
                continue
            parts = line.split()
            if len(parts) >= 5 and parts[0] == 'open':
                # open tcp 443 1.2.3.4 ...
                port = parts[2]
                ip = parts[3]
                try:
                    port_int = int(port)
                except ValueError:
                    continue
                open_batch.append((ip, port_int))
                count_total += 1

                if len(open_batch) >= BATCH_SIZE:
                    asyncio.run(filter_batch_and_write(open_batch, fout))
                    open_batch.clear()

        # masscan ç»“æŸ
        proc.wait()

        # æ”¶å°¾ï¼šå¤„ç†å‰©ä½™ batch
        if open_batch:
            asyncio.run(filter_batch_and_write(open_batch, fout))
            open_batch.clear()

    # ç­‰å¾…è¿›åº¦æ³µçº¿ç¨‹åƒå®Œæœ€åçš„ stderr
    thr.join(timeout=2)

    elapsed = time.time() - t0
    print(f"[+] å…¨éƒ¨æ‰«ææ£€æµ‹å®Œæˆï¼Œæ€»è®°å½•æ‰«æ {count_total} æ¡ã€‚ç”¨æ—¶ {elapsed:.2f} ç§’ã€‚")
    if proc.returncode != 0:
        print(f"[WARN] masscan è¿”å›ç  {proc.returncode}")


# -------------------- VLESS è§£æ / æ„é€  / æµ‹è¯• --------------------
def parse_vless_url(vless_url: str) -> Dict:
    u = urlparse(vless_url)
    qs = {k: v[0] for k, v in parse_qs(u.query).items()}
    return {
        "uuid": u.username or "",
        "address": u.hostname or "",
        "port": int(u.port) if u.port else 0,
        "params": qs,
        "fragment": u.fragment or "",
        "raw": vless_url
    }


def build_vless_link(uuid: str, ip: str, port: int, params: Dict, fragment: str) -> str:
    query = urlencode(params, doseq=True, safe="%/:?&=")
    link = f"vless://{uuid}@{ip}:{port}"
    if query:
        link += f"?{query}"
    if fragment:
        link += f"#{fragment}"
    return link


def sanitize_filename(s: str) -> str:
    return re.sub(r"[^A-Za-z0-9_.-]+", "_", s)


def build_xray_config_for_vless(ip: str, port: int, base: Dict, local_socks_port: int) -> Dict:
    uuid = base["uuid"]
    params = base["params"]
    network = params.get("type", "tcp").lower()
    security = params.get("security", "").lower()
    host_hdr = params.get("host", base["address"]) or base["address"]
    path = unquote(params.get("path", "/") or "/")
    allow_insecure = (params.get("allowInsecure", "0") == "1")
    sni = params.get("sni", host_hdr) or host_hdr

    stream_settings = {"network": network}
    if security == "tls" or params.get("security", "").lower() == "tls":
        tls_settings = {
            "allowInsecure": allow_insecure,
            "serverName": sni,
            "alpn": ["http/1.1"],
            "fingerprint": "chrome"
        }
        stream_settings["security"] = "tls"
        stream_settings["tlsSettings"] = tls_settings
    if network == "ws":
        stream_settings["wsSettings"] = {"path": path, "headers": {"Host": host_hdr}}

    inbounds = [{
        "port": local_socks_port,
        "listen": "127.0.0.1",
        "protocol": "socks",
        "settings": {"udp": True}
    }]
    outbounds = [{
        "protocol": "vless",
        "settings": {
            "vnext": [{
                "address": ip,
                "port": int(port),
                "users": [{"id": uuid, "encryption": params.get("encryption", "none")}]
            }]
        },
        "streamSettings": stream_settings
    }]
    return {"log": {"loglevel": "warning"}, "inbounds": inbounds, "outbounds": outbounds}


def run_xray_with_config(cfg: Dict, cfg_path: str) -> subprocess.Popen:
    with open(cfg_path, "w", encoding="utf-8") as f:
        json.dump(cfg, f, ensure_ascii=False, indent=2)
    proc = subprocess.Popen(
        [XRAY_PATH, "run", "-c", cfg_path],
        stdout=subprocess.DEVNULL,
        stderr=subprocess.DEVNULL,
        preexec_fn=os.setsid
    )
    return proc


def stop_proc(proc: subprocess.Popen):
    try:
        os.killpg(os.getpgid(proc.pid), signal.SIGTERM)
    except Exception:
        try:
            proc.terminate()
        except Exception:
            pass
    try:
        proc.wait(timeout=3)
    except Exception:
        try:
            os.killpg(os.getpgid(proc.pid), signal.SIGKILL)
        except Exception:
            pass


# -------------------- å¥åº·æ£€æµ‹ --------------------
def wait_socks_ready(port: int, timeout: float = SOCKS_READY_TIMEOUT) -> bool:
    deadline = time.time() + timeout
    while time.time() < deadline:
        s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        s.settimeout(0.2)
        try:
            s.connect(("127.0.0.1", port))
            s.close()
            return True
        except Exception:
            time.sleep(0.1)
        finally:
            try:
                s.close()
            except Exception:
                pass
    return False


def curl_once(url: str, port: int) -> Tuple[bool, int, float]:
    cmd = [
        CURL_CMD,
        "-x", f"socks5h://127.0.0.1:{port}",
        "--max-time", str(CURL_TIMEOUT),
        "-s", "-o", "/dev/null",
        "-w", "%{http_code} %{time_total}",
        "--http2",
        "-A", USER_AGENT,
        url
    ]
    try:
        r = subprocess.run(cmd, capture_output=True, text=True)
        out = (r.stdout or "").strip()
        parts = out.split()
        code = int(parts[0]) if parts and parts[0].isdigit() else -1
        t_total = float(parts[1]) if len(parts) > 1 else CURL_TIMEOUT
        ok = (code in SUCCESS_HTTP_CODES)
        return ok, code, t_total
    except Exception:
        return False, -1, CURL_TIMEOUT


def curl_check_stable(url: str, port: int, tries: int = PER_URL_TRIES) -> bool:
    for _ in range(tries):
        ok, code, t_total = curl_once(url, port)
        if not ok:
            return False
    return True


def parse_ip_port(line: str) -> Optional[Tuple[str, int]]:
    s = line.strip()
    if not s:
        return None
    if s.startswith("["):  # IPv6
        try:
            i = s.index("]")
            ip = s[1:i]
            rem = s[i + 1:]
            if rem.startswith(":"):
                return ip, int(rem[1:])
            return None
        except Exception:
            return None
    else:
        if ":" not in s:
            return None
        a, b = s.rsplit(":", 1)
        try:
            return a, int(b)
        except Exception:
            return None


def test_one_replaced_node(ip_port: str, base_parsed: Dict, local_port: int, tmp_dir: str) -> bool:
    parsed = parse_ip_port(ip_port)
    if not parsed:
        return False
    ip, port = parsed
    cfg = build_xray_config_for_vless(ip, port, base_parsed, local_port)
    cfg_name = os.path.join(tmp_dir, f"x_{sanitize_filename(ip_port)}.json")
    proc = None
    try:
        proc = run_xray_with_config(cfg, cfg_name)
        if not wait_socks_ready(local_port, SOCKS_READY_TIMEOUT):
            return False
        for url in TEST_URLS:
            if not curl_check_stable(url, local_port, PER_URL_TRIES):
                return False
        return True
    except Exception:
        return False
    finally:
        if proc:
            stop_proc(proc)
        try:
            os.remove(cfg_name)
        except Exception:
            pass


# ------------------ A è„šæœ¬ ------------------
def parse_vless_line_for_a(line: str) -> Optional[Tuple[str, int, str]]:
    s = line.strip()
    if not s:
        return None
    m = re.match(r'^vless://[^@]+@([\d\.]+):(\d+)(\?.*)?$', s)
    if m:
        return m.group(1), int(m.group(2)), s
    m2 = re.match(r'^vless://[^@]+@([\d\.]+):(\d+)(#.*)?$', s)
    if m2:
        return m2.group(1), int(m2.group(2)), s
    return None


def load_bgp_file(filename: str) -> OrderedDict:
    bgp_map = OrderedDict()
    if not os.path.exists(filename):
        print(f"[WARN] BGP æ–‡ä»¶ {filename} ä¸å­˜åœ¨")
        return bgp_map
    cur = None
    with open(filename, "r", encoding="utf-8") as f:
        for raw in f:
            line = raw.strip()
            if not line:
                cur = None
                continue
            if line.endswith(":"):
                cur = line.rstrip(":")
                bgp_map[cur] = []
                continue
            if cur:
                try:
                    net = ipaddress.ip_network(line, strict=False)
                    bgp_map[cur].append(net)
                except Exception:
                    print(f"[WARN] BGP æ— æ³•è§£æç½‘æ®µ: {line}")
    return bgp_map


def find_vendor_for_ip(ip: str, bgp_map: OrderedDict) -> Optional[str]:
    try:
        ip_obj = ipaddress.ip_address(ip)
    except Exception:
        return None
    for vendor, nets in bgp_map.items():
        for net in nets:
            if ip_obj in net:
                return vendor
    return None


def replace_fragment(line: str, new_name: str) -> str:
    m = re.match(r'^(.*?)(?:#.*)?$', line)
    if m:
        return f"{m.group(1)}#{new_name}"
    return line


def run_a_filter_on_file(input_file: str, bgp_file: str, output_file: str) -> int:
    parsed = {}
    with open(input_file, "r", encoding="utf-8") as fin:
        for raw in fin:
            raw = raw.strip()
            if not raw:
                continue
            res = parse_vless_line_for_a(raw)
            if not res:
                continue
            ip, port, line = res
            key = (ip, port)
            if key not in parsed:   # âœ… åªåœ¨å®Œå…¨ç›¸åŒ ip+port æ—¶å»é‡
                parsed[key] = line

    bgp_map = load_bgp_file(bgp_file)

    vendor_nodes = defaultdict(list)
    no_vendor = []
    for (ip, port), line in parsed.items():
        vendor = find_vendor_for_ip(ip, bgp_map)
        if vendor:
            vendor_nodes[vendor].append((ip, line))
        else:
            no_vendor.append((ip, line))

    output_lines = []
    for vendor in bgp_map.keys():
        if vendor not in vendor_nodes:
            continue
        for idx, (ip, line) in enumerate(vendor_nodes[vendor], start=1):
            new_name = f"HK-ä¼˜åŒ–MAX-{vendor}-{idx:02d}"
            output_lines.append(replace_fragment(line, new_name))
    for idx, (ip, line) in enumerate(no_vendor, start=1):
        new_name = f"HK-ä¼˜åŒ–-{idx:02d}"
        output_lines.append(replace_fragment(line, new_name))

    with open(output_file, "w", encoding="utf-8") as fout:
        for l in output_lines:
            fout.write(l + "\n")
    return len(output_lines)



# ------------------ è¾…åŠ©ç»Ÿè®¡ ------------------
def count_vendors(filename: str, bgp_file: str) -> dict[str, int]:
    bgp_map = load_bgp_file(bgp_file)
    counts = {}
    if not os.path.exists(filename):
        return counts
    with open(filename, "r", encoding="utf-8") as f:
        for line in f:
            if not line.strip():
                continue
            parsed = parse_vless_line_for_a(line)
            if not parsed:
                continue
            ip, _, _ = parsed
            vendor = find_vendor_for_ip(ip, bgp_map) or "æœªåˆ†ç±»"
            counts[vendor] = counts.get(vendor, 0) + 1
    return counts


# ------------------ ä¸»æµç¨‹ ------------------
def format_elapsed(seconds: float) -> str:
    if seconds < 60:
        return f"{int(seconds)}ç§’"
    elif seconds < 3600:
        m, s = divmod(int(seconds), 60)
        return f"{m}åˆ†é’Ÿ{s}ç§’"
    else:
        h, rem = divmod(int(seconds), 3600)
        m = rem // 60
        return f"{h}å°æ—¶{m}åˆ†é’Ÿ"


def main():
    start_time = time.time()

    # è¯»å–å¹¶è§£æå›ºå®š BASE_VLESS
    base_parsed = parse_vless_url(BASE_VLESS)

    # ---- åœ¨ä»»ä½•ä¿®æ”¹ okcf.txt ä¹‹å‰ï¼Œè®°å½•åˆå§‹å•†å®¶åˆ†å¸ƒ & åˆå§‹èŠ‚ç‚¹æ•°é‡ ----
    # åˆå§‹èŠ‚ç‚¹æ•° = okcf.txt åœ¨è„šæœ¬è¿è¡Œå‰çš„è¡Œæ•°ï¼ˆip:portï¼‰
    if os.path.exists(OK_FILE):
        with open(OK_FILE, "r", encoding="utf-8") as f:
            initial_ok_lines = [ln.strip() for ln in f if ln.strip()]
    else:
        initial_ok_lines = []
    initial_count = len(initial_ok_lines)

    # ä¸ºåˆå§‹å•†å®¶åˆ†å¸ƒç”Ÿæˆä¸´æ—¶ vless æ–‡ä»¶å¹¶ç»Ÿè®¡ï¼ˆä¿æŒåŸæ¥ç»Ÿè®¡é€»è¾‘ï¼‰
    os.makedirs(TMP_DIR, exist_ok=True)
    temp_initial_vless = os.path.join(TMP_DIR, "initial_vless.txt")
    with open(temp_initial_vless, "w", encoding="utf-8") as f:
        for ipport in initial_ok_lines:
            parsed = parse_ip_port(ipport)
            if not parsed:
                continue
            ip, port = parsed
            vlink = build_vless_link(base_parsed["uuid"], ip, port, base_parsed["params"], base_parsed["fragment"])
            f.write(vlink + "\n")
    # run_a_filter_on_file ä¼šå¯¹æ–‡ä»¶é‡å‘½å/å»é‡ï¼Œè¿”å›æœ€ç»ˆæ•°é‡ï¼ˆæˆ‘ä»¬åœ¨ä¸´æ—¶æ–‡ä»¶ä¸Šè¿è¡Œï¼Œä»¥ä¿æŒç»Ÿè®¡æ–¹å¼ä¸€è‡´ï¼‰
    run_a_filter_on_file(temp_initial_vless, BGP_FILE, temp_initial_vless)
    initial_vendor_count = count_vendors(temp_initial_vless, BGP_FILE)

    print("[STEP 1] å¯åŠ¨ masscan æ‰«æå¹¶è¿‡æ»¤ï¼ˆç”Ÿæˆ cf_ip.txtï¼‰...")
    if not shutil.which(MASSCAN_PATH):
        print(f"[ERROR] æœªæ‰¾åˆ° masscan (è·¯å¾„: {MASSCAN_PATH})")
        return
    run_masscan_scan_and_filter()

    if not os.path.exists(CF_IP_FILE):
        print(f"[ERROR] æ‰«æåæœªç”Ÿæˆ {CF_IP_FILE}ï¼Œé€€å‡ºã€‚")
        return

    # è¯»å– cf_ip.txtï¼Œä½†æŒ‰ ip:port å»é‡ï¼ˆç”¨æˆ·è¦æ±‚ï¼šç›¸åŒ ip ä¸åŒ port è§†ä¸ºä¸åŒï¼‰
    seen = set()
    ipports = []
    with open(CF_IP_FILE, "r", encoding="utf-8") as f:
        for line in f:
            s = line.strip()
            if not s:
                continue
            # åªæŒ‰ ip:port å»é‡
            if s not in seen:
                seen.add(s)
                ipports.append(s)

    if not ipports:
        print("[INFO] cf_ip.txt ä¸ºç©ºï¼Œæ— éœ€åç»­æ£€æµ‹ã€‚")
        return

    # ç°æœ‰ okcf.txt çš„å†…å®¹ï¼ˆç”¨æ¥é¿å…é‡å¤å†™å…¥ï¼‰
    exist_ok_set = set()
    if os.path.exists(OK_FILE):
        with open(OK_FILE, "r", encoding="utf-8") as f:
            for l in f:
                if l.strip():
                    exist_ok_set.add(l.strip())

    # å¹¶å‘æµ‹è¯• ip:port åˆ—è¡¨ï¼Œæµ‹è¯•é€šè¿‡åˆ™åŠ å…¥ final_ok_linksï¼ˆip:port å½¢å¼ï¼‰
    final_ok_links = []

    os.makedirs(TMP_DIR, exist_ok=True)
    port_pool = queue.Queue()
    for i in range(MAX_WORKERS):
        port_pool.put(LOCAL_SOCKS_BASE + i)

    def task_test_ipport(ipport: str):
        local = port_pool.get()
        try:
            ok = test_one_replaced_node(ipport, base_parsed, local, TMP_DIR)
            return ipport, ok
        finally:
            port_pool.put(local)

    futures = []
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as ex:
        for ipp in ipports:
            futures.append(ex.submit(task_test_ipport, ipp))
        for fut in as_completed(futures):
            ipp, ok = fut.result()
            if ok:
                final_ok_links.append(ipp)

    # å°†é€šè¿‡çš„ ip:port å†™å…¥ okcf.txtï¼ˆä¿æŒå·²æœ‰çš„ä¸é‡å¤è¿½åŠ ï¼‰
    if final_ok_links:
        # ä¿è¯æ–‡ä»¶å­˜åœ¨
        if not os.path.exists(OK_FILE):
            open(OK_FILE, "a").close()
        with open(OK_FILE, "a", encoding="utf-8") as f:
            for ipp in final_ok_links:
                if ipp not in exist_ok_set:
                    f.write(ipp + "\n")
                    exist_ok_set.add(ipp)

    # è¯»å– okcf.txt çš„æœ€ç»ˆå…¨éƒ¨å†…å®¹ï¼ˆä½œä¸ºæœ€ç»ˆèŠ‚ç‚¹é›†ï¼‰
    with open(OK_FILE, "r", encoding="utf-8") as f:
        all_ok_final = [ln.strip() for ln in f if ln.strip()]
    final_count = len(all_ok_final)

    # ä¸ºäº†ä¿æŒâ€œèŠ‚ç‚¹å˜åŒ–å’Œæœ€ç»ˆå•†å®¶åˆ†å¸ƒâ€ä¸åŸæ¥é€»è¾‘ä¸€è‡´ï¼š
    # æŠŠ okcf.txt ä¸­çš„ ip:port è½¬æˆ vless è¡Œå†™å…¥ä¸´æ—¶æ–‡ä»¶ï¼Œè¿è¡Œ A è„šæœ¬é€»è¾‘ï¼ˆé‡å‘½å/å»é‡ï¼‰ï¼Œç„¶åç»Ÿè®¡å•†å®¶
    temp_final_vless = os.path.join(TMP_DIR, "final_vless.txt")
    with open(temp_final_vless, "w", encoding="utf-8") as f:
        for ipport in all_ok_final:
            parsed = parse_ip_port(ipport)
            if not parsed:
                continue
            ip, port = parsed
            vlink = build_vless_link(base_parsed["uuid"], ip, port, base_parsed["params"], base_parsed["fragment"])
            f.write(vlink + "\n")
    # è¿è¡Œ A è„šæœ¬çš„å»é‡/é‡å‘½åé€»è¾‘ï¼ˆåœ¨ä¸´æ—¶æ–‡ä»¶ä¸Šæ“ä½œï¼‰
    final_count_after_a = run_a_filter_on_file(temp_final_vless, BGP_FILE, temp_final_vless)
    final_vendor_count = count_vendors(temp_final_vless, BGP_FILE)

    # ---- èŠ‚ç‚¹å˜åŒ–è®¡ç®—ï¼šæœ€ç»ˆåˆ†å¸ƒ - åˆå§‹åˆ†å¸ƒ ----
    diff_entries = []
    vendors_union = set(initial_vendor_count) | set(final_vendor_count)
    for vendor in vendors_union:
        before = initial_vendor_count.get(vendor, 0)
        after = final_vendor_count.get(vendor, 0)
        diff = after - before
        if diff != 0:
            diff_entries.append((vendor, diff))

    diff_lines = []
    for vendor, diff in diff_entries:
        emoji = "ğŸŸ¢" if diff > 0 else "ğŸ”´"
        diff_lines.append(f"{emoji} {vendor}ï¼š{diff}")
    diff_text = "\n".join(diff_lines) if diff_lines else "æ— å˜åŒ–"

    try:
        os.rmdir(TMP_DIR)
    except Exception:
        pass

    elapsed = time.time() - start_time
    elapsed_str = format_elapsed(elapsed)

    vendor_lines = []
    for vendor, count in sorted(final_vendor_count.items(), key=lambda x: x[1], reverse=True):
        if count > 0:
            vendor_lines.append(f"ğŸ·ï¸ {vendor}ï¼š{count}")
    vendor_text = "\n".join(vendor_lines) if vendor_lines else "æ— "

    msg = (
        f"ğŸ“¡ã€CloudFlare-å¾ªç¯æ‰«æã€‘\n"
        f"ğŸ“¡ã€æœåŠ¡å™¨ã€‘ äººæ°‘äº‘-æ³•å›½\n"
        f"ğŸ”¹ åˆå§‹èŠ‚ç‚¹ï¼š{initial_count}\n"
        f"ğŸ“¦ æœ€ç»ˆèŠ‚ç‚¹ï¼š{final_count}\n"
        f"â±ï¸ è€—æ—¶ï¼š{elapsed_str}\n\n"
        f"ğŸ“Š èŠ‚ç‚¹å˜åŒ–\n{diff_text}\n\n"
        f"ğŸ“ æœ€ç»ˆå•†å®¶åˆ†å¸ƒ\n{vendor_text}"
    )
    print(msg)
    send_telegram(msg)


if __name__ == "__main__":
    while True:
        # è¿›å…¥ main() å‰æ¸…ç©ºæ—¥å¿—
        open(LOG_FILE, "w").close()
        main()
        time.sleep(60)
